#!/usr/bin/env python3
# -*- coding: utf-8; py-indent-offset: 4 -*-
#
# Author:  Linuxfabrik GmbH, Zurich, Switzerland
# Contact: info (at) linuxfabrik (dot) ch
#          https://www.linuxfabrik.ch/
# License: The Unlicense, see LICENSE file.

# https://github.com/Linuxfabrik/monitoring-plugins/blob/main/CONTRIBUTING.rst

"""See the check's README for more details.
"""

import argparse  # pylint: disable=C0413
import os  # pylint: disable=C0413
import platform  # pylint: disable=C0413
import sys  # pylint: disable=C0413

import lib.args  # pylint: disable=C0413
import lib.base  # pylint: disable=C0413
import lib.cache  # pylint: disable=C0413
import lib.db_sqlite  # pylint: disable=C0413
import lib.disk  # pylint: disable=C0413
import lib.human  # pylint: disable=C0413
import lib.time  # pylint: disable=C0413
import lib.txt  # pylint: disable=C0413
import lib.version  # pylint: disable=C0413
from lib.globals import (STATE_CRIT, STATE_OK,  # pylint: disable=C0413
                          STATE_UNKNOWN, STATE_WARN)

try:
    import psutil
except ImportError as e:
    lib.base.cu('Python module "psutil" is not installed.')


__author__ = 'Linuxfabrik GmbH, Zurich/Switzerland'
__version__ = '2024040101'

DESCRIPTION = """Checks disk I/O. If the bandwidth usage of a disk is above the specified threshold
                 (as a percentage of the maximum bandwidth measured) for a certain period of time,
                 an alarm is triggered."""

DEFAULT_CACHE_EXPIRE = 90
DEFAULT_COUNT = 5 # measurements; if check runs once per minute, this is a 5 minute interval
DEFAULT_WARN = 80 # %
DEFAULT_CRIT = 90 # %
DEFAULT_MATCH = ''
DEFAULT_TOP = 5


def parse_args():
    """Parse command line arguments using argparse.
    """
    parser = argparse.ArgumentParser(description=DESCRIPTION)

    parser.add_argument(
        '-V', '--version',
        action='version',
        version='{0}: v{1} by {2}'.format('%(prog)s', __version__, __author__)
    )

    parser.add_argument(
        '--always-ok',
        help='Always returns OK.',
        dest='ALWAYS_OK',
        action='store_true',
        default=False,
    )

    parser.add_argument(
        '--count',
        help='Number of times the value must exceed specified thresholds before alerting. '
             'Default: %(default)s',
        dest='COUNT',
        type=int,
        default=DEFAULT_COUNT,
    )

    parser.add_argument(
        '--critical',
        help='Threshold for disk bandwidth saturation (over the last `--count` measurements) as a '
             'percentage of the maximum bandwidth the disk can support. '
             'Default: >= %(default)s',
        dest='CRIT',
        type=int,
        default=DEFAULT_CRIT,
    )

    parser.add_argument(
        '--match',
        help='Match on disk names. ' + lib.args.help('--match') + \
             'Default: %(default)s',
        dest='MATCH',
        default=DEFAULT_MATCH,
    )

    parser.add_argument(
        '--top',
        help='List x "Top processes that generated the most I/O traffic". '
             'Default: %(default)s',
        dest='TOP',
        type=int,
        default=DEFAULT_TOP,
    )

    parser.add_argument(
        '--warning',
        help='Threshold for disk bandwidth saturation (over the last `--count` measurements) as a '
             'percentage of the maximum bandwidth the disk can support. '
             'Default: >= %(default)s',
        dest='WARN',
        type=int,
        default=DEFAULT_WARN,
    )

    return parser.parse_args()


def get_max_bandwidth(disk, current_bandwidth):
    """Store the maximum measured bandwidth for the secific disk in cache table.
    """
    historic_bandwidth = lib.cache.get(
        'disk-io-{}-bandwidth-max'.format(disk),
        filename='linuxfabrik-monitoring-plugins-disk-io.db',
    )
    # Disk should be capable of at least 10 MB/sec (if no info is provided)
    max_bandwidth = max(
        int(historic_bandwidth),
        int(current_bandwidth),
        10 * 1024 * 1024,
    )
    lib.cache.set(
        'disk-io-{}-bandwidth-max'.format(disk),
        max_bandwidth,
        filename='linuxfabrik-monitoring-plugins-disk-io.db',
    )
    return max_bandwidth


def get_rate(ts1, ts2, rr1, rr2, wr1, wr2, r1, r2, w1, w2):
    """Given two read-, write- and timestamp-values, return the read- and write-rate
    plus bandwidth and iops.
    """
    timediff = abs(ts1 - ts2) # in seconds
    if timediff == 0:
        return 0, 0, 0, 0, 0, 0
    rr = abs(int(float(rr1 - rr2) / timediff))
    wr = abs(int(float(wr1 - wr2) / timediff))
    r = abs(int(float(r1 - r2) / timediff))
    w = abs(int(float(w1 - w2) / timediff))

    return timediff, rr, wr, rr + wr, r, w


def top(count):
    """Get top X processes that generated the most I/O traffic.
    """
    cnt = {}
    try:
        for p in [x.as_dict(attrs=['name', 'io_counters']) for x in psutil.process_iter()]:
            if p['io_counters']:
                if p['name'] not in cnt.keys():
                    cnt[p['name']] = {'r': 0, 'w': 0}
                cnt[p['name']]['r'] += p['io_counters'].read_bytes
                cnt[p['name']]['w'] += p['io_counters'].write_bytes
    except psutil.NoSuchProcess:
        pass
    # cnt.items: [
    #     ('WebKitNetworkProcess', {'r': 1716224, 'w': 0}),
    #     ('ibus-x11', {'r': 0, 'w': 0}), ...
    if not cnt:
        return ''
    cnt = sorted(cnt.items(), key=lambda x: x[1]['r']+x[1]['w'], reverse=True)
    if cnt[0][1]['r'] + cnt[0][1]['w'] > 0: # don't print "1. any-proc: 0.0B/0.0B (r/w)"
        msg = '\nTop {} processes that generate the most I/O traffic:\n'.format(count)
        for i, (key, value) in enumerate(cnt):
            if i > count - 1:
                break
            msg += '{}. {}: {}/{} (r/w)\n'.format(
                i + 1,
                key,
                lib.human.bytes2human(value['r']),
                lib.human.bytes2human(value['w']),
            )
    return msg


def main():
    """The main function. Hier spielt die Musik.
    """

    # parse the command line, exit with UNKNOWN if it fails
    try:
        args = parse_args()
    except SystemExit:
        sys.exit(STATE_UNKNOWN)

    # Kernel 5.5 added 2 more fields to /proc/diskstats, requiring another
    # change after the one for 4.18, which recently added 4 fields.
    # To prevent "ValueError: not sure how to interpret line",
    # we check the version of psutil first.
    if lib.base.LINUX and all([
            lib.version.version(platform.release()) >= lib.version.version('4.18.0'),
            lib.version.version(psutil.__version__) < lib.version.version('5.7.0')
        ]):
        lib.base.oao('Nothing checked. Running Kernel >= 4.18, this check needs the Python module '
            'psutil v5.7.0+ (installed {}; have a look at '
            'https://github.com/giampaolo/psutil/pull/1665 '
            'for details).'.format(psutil.__version__), STATE_OK, always_ok=args.ALWAYS_OK)

    # create the perfdata table
    conn = lib.base.coe(
        lib.db_sqlite.connect(filename='linuxfabrik-monitoring-plugins-disk-io.db')
    )
    definition = '''
            bd                  TEXT NOT NULL,
            dmd                 TEXT,
            mp                  TEXT,
            read_count          INT DEFAULT 0,
            write_count         INT DEFAULT 0,
            busy_time           INT DEFAULT 0,
            read_bytes          INT DEFAULT 0,
            read_merged_count   INT DEFAULT 0,
            read_time           INT DEFAULT 0,
            write_bytes         INT DEFAULT 0,
            write_merged_count  INT DEFAULT 0,
            write_time          INT DEFAULT 0,
            timestamp           INT DEFAULT 0
        '''
    lib.base.coe(lib.db_sqlite.create_table(conn, definition, drop_table_first=False))
    lib.base.coe(lib.db_sqlite.create_index(conn, 'bd'))

    # init some vars
    msg = 'No I/O on `{}`.'.format(args.MATCH) if args.MATCH else 'No I/O.'
    perfdata = ''
    state = STATE_OK
    table_values = []
    compiled_regex = lib.base.coe(lib.txt.compile_regex(args.MATCH))
    now = lib.time.now()
    busiest_disk = 0 # disk with the highest sum of r/w: show this on top later on
    disks = []

    # fetch data
    try:
        disk_io_counters = psutil.disk_io_counters(perdisk=True)
    except ValueError:
        lib.base.cu('psutil raised an error')

    # analyze and enrich data, store it to database
    real_disks = lib.disk.get_real_disks()

    # if match argument is supplied, try the match on all interfaces from pustil disk_io_counters
    # do not try the match if the interface is already included in real_disks 
    if args.MATCH:
        for disk in disk_io_counters.keys():
            if lib.base.coe(lib.txt.match_regex(compiled_regex, disk)) and not any(disk in x['bd'] for x in real_disks):
                real_disks.append({'bd': disk, 'dmd': '', 'mp': ''})

    for disk in real_disks:
        psutil_name = os.path.basename(disk['bd'])

        # disks we have to match
        if args.MATCH \
        and all((
            not lib.base.coe(lib.txt.match_regex(compiled_regex, psutil_name)),
            not lib.base.coe(lib.txt.match_regex(compiled_regex, disk['dmd'])),
            not lib.base.coe(lib.txt.match_regex(compiled_regex, disk['mp'])),
        )):
            continue

        if psutil_name not in disk_io_counters:
            continue

        data = {}
        data['bd'] = disk['bd']
        data['dmd'] = disk['dmd']
        data['mp'] = disk['mp']
        data['read_count'] = getattr(disk_io_counters[psutil_name], 'read_count', 0)
        data['write_count'] = getattr(disk_io_counters[psutil_name], 'write_count', 0)
        data['busy_time'] = getattr(disk_io_counters[psutil_name], 'busy_time', 0)
        data['read_bytes'] = getattr(disk_io_counters[psutil_name], 'read_bytes', 0)
        data['read_merged_count'] = getattr(disk_io_counters[psutil_name], 'read_merged_count', 0)
        data['read_time'] = getattr(disk_io_counters[psutil_name], 'read_time', 0)
        data['write_bytes'] = getattr(disk_io_counters[psutil_name], 'write_bytes', 0)
        data['write_merged_count'] = getattr(disk_io_counters[psutil_name], 'write_merged_count', 0)
        data['write_time'] = getattr(disk_io_counters[psutil_name], 'write_time', 0)
        data['timestamp'] = now
        disks.append(disk)
        # store it to database
        lib.base.coe(lib.db_sqlite.insert(conn, data))

    # truncate old data (just keep args.COUNT for each disk) and commit
    lib.base.coe(lib.db_sqlite.cut(conn, _max=args.COUNT*len(disks)))
    lib.base.coe(lib.db_sqlite.commit(conn))

    # from here on just working on the database

    # warn about a "count" period/amount of time, not about the current situation above
    # (what might be a peak only)
    for disk in disks:
       # get all historical data rows for a specific disk, newest item first
        data = lib.base.coe(lib.db_sqlite.select(
            conn,
            '''
            SELECT *
            FROM perfdata
            WHERE bd = :name
            ORDER BY timestamp DESC
            ''',
            {'name': disk['bd']},
        ))
        if len(data) < 2:
            lib.db_sqlite.close(conn)
            lib.base.oao('Waiting for more data.', state)

        # calculate current rates (like "load1")
        timediff, read_bytes_per_second1, write_bytes_per_second1, bandwidth1, read_per_second1, write_per_second1 = get_rate(
            data[0]['timestamp'],
            data[1]['timestamp'],
            data[0]['read_bytes'],
            data[1]['read_bytes'],
            data[0]['write_bytes'],
            data[1]['write_bytes'],
            data[0]['read_count'],
            data[1]['read_count'],
            data[0]['write_count'],
            data[1]['write_count']
        )
        if timediff <= 0:
            # often happens after a reboot
            lib.db_sqlite.close(conn)
            lib.base.oao('Waiting for more data.', state)

        # get the maximum disk bandwidth in disks' history
        bandwidth_max = get_max_bandwidth(disk['bd'], bandwidth1)

        if bandwidth1 > busiest_disk:
            # get the current busiest disk for the first line of the message
            msg = '{}: {}/s read1, {}/s write1, {}/s total, {}/s max, {}/s readops, {}/s writeops'.format(
                disk['bd'],
                lib.human.bytes2human(read_bytes_per_second1),
                lib.human.bytes2human(write_bytes_per_second1),
                lib.human.bytes2human(bandwidth1),
                lib.human.bytes2human(bandwidth_max),
                read_per_second1,
                write_per_second1
            )
            if args.MATCH:
                msg += ' (disks matching `{}`).'.format(args.MATCH)
            busiest_disk = bandwidth1

        # calculate read/write rate over the entire period (like "load5")
        if len(data) != args.COUNT:
            # not enough data yet
            continue
        timediff, read_bytes_per_second5, write_bytes_per_second5, bandwidth5, read_per_second5, write_per_second5 = get_rate(
            data[0]['timestamp'],
            data[args.COUNT - 1]['timestamp'],
            data[0]['read_bytes'],
            data[args.COUNT - 1]['read_bytes'],
            data[0]['write_bytes'],
            data[args.COUNT - 1]['write_bytes'],
            data[0]['read_count'],
            data[args.COUNT - 1]['read_count'],
            data[0]['write_count'],
            data[args.COUNT - 1]['write_count'],
        )
        if timediff <= 0:
            # often happens after a reboot
            lib.db_sqlite.close(conn)
            lib.base.oao('Waiting for more data.', state)

        # get state based on max measured I/O values
        local_state = lib.base.get_state(
            bandwidth5,
            bandwidth_max * args.WARN / 100,
            bandwidth_max * args.CRIT / 100,
        )
        state = lib.base.get_worst(local_state, state)

        bd = disk['bd'].replace('/dev/', '')
        table_values.append({
            'bd': bd,
            'dmd': disk['dmd'].replace('/dev/mapper/', ''),
            'mp': disk['mp'],
            'max': lib.human.bytes2human(bandwidth_max),
            'rr1': lib.human.bytes2human(read_bytes_per_second1),
            'wr1': lib.human.bytes2human(write_bytes_per_second1),
            'rr5': lib.human.bytes2human(read_bytes_per_second5),
            'wr5': lib.human.bytes2human(write_bytes_per_second5),
            'tr5': lib.human.bytes2human(bandwidth5) + lib.base.state2str(local_state, prefix=' '),
            'r1': read_per_second1,
            'w1': write_per_second1,
            'r5': read_per_second5,
            'w5': write_per_second5,
        })

        # perfdata
        try:
            perfdata += lib.base.get_perfdata('{}_busy_time'.format(bd), data[0]['busy_time'], 'c', None, None, 0, None) # pylint: disable=C0301
            perfdata += lib.base.get_perfdata('{}_read_bytes'.format(bd), data[0]['read_bytes'], 'c', None, None, 0, None) # pylint: disable=C0301
            perfdata += lib.base.get_perfdata('{}_read_count'.format(bd), data[0]['read_count'], 'c', None, None, 0, None) # pylint: disable=C0301
            perfdata += lib.base.get_perfdata('{}_read_time'.format(bd), data[0]['read_time'], 'c', None, None, 0, None) # pylint: disable=C0301
            perfdata += lib.base.get_perfdata('{}_write_bytes'.format(bd), data[0]['write_bytes'], 'c', None, None, 0, None) # pylint: disable=C0301
            perfdata += lib.base.get_perfdata('{}_write_count'.format(bd), data[0]['write_count'], 'c', None, None, 0, None) # pylint: disable=C0301
            perfdata += lib.base.get_perfdata('{}_write_time'.format(bd), data[0]['write_time'], 'c', None, None, 0, None) # pylint: disable=C0301
        except:
            pass

    lib.db_sqlite.close(conn)

    # build the message
    msg = msg + '\n\n'
    if len(table_values) > 0:
        msg += lib.base.get_table(
            table_values,
            [
                'bd',
                'mp',
                'dmd',
                'max',
                'rr1',
                'wr1',
                'rr5',
                'wr5',
                'tr5',
                'r1',
                'w1',
                'r5',
                'w5'
            ],
            header=[
                'Name',
                'MntPnts',
                'DvMppr',
                'RWmax/s',
                'R1/s',
                'W1/s',
                'R{}/s'.format(args.COUNT),
                'W{}/s'.format(args.COUNT),
                'RW{}/s'.format(args.COUNT),
                'R1/s',
                'W1/s',
                'R{}/s'.format(args.COUNT),
                'W{}/s'.format(args.COUNT)
            ],
        )

    # Top X processes that generated the most I/O traffic
    msg += top(args.TOP)

    # over and out
    lib.base.oao(msg.replace('\n\n\n', '\n\n'), state, perfdata, always_ok=args.ALWAYS_OK)


if __name__ == '__main__':
    try:
        main()
    except Exception as e:
        lib.base.cu()
